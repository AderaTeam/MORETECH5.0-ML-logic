{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:36.260955Z","iopub.status.busy":"2023-10-15T01:24:36.260637Z","iopub.status.idle":"2023-10-15T01:24:47.631277Z","shell.execute_reply":"2023-10-15T01:24:47.630297Z","shell.execute_reply.started":"2023-10-15T01:24:36.260930Z"},"trusted":true},"outputs":[],"source":["import time\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import resnet50, efficientnet, mobilenet\n","from PIL.ImageDraw import Draw\n","from keras.layers import *\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:47.633670Z","iopub.status.busy":"2023-10-15T01:24:47.633042Z","iopub.status.idle":"2023-10-15T01:24:47.653139Z","shell.execute_reply":"2023-10-15T01:24:47.652343Z","shell.execute_reply.started":"2023-10-15T01:24:47.633645Z"},"trusted":true},"outputs":[],"source":["META_FILE = 'datasets/labels.csv'\n","data = pd.read_csv(META_FILE)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:47.655117Z","iopub.status.busy":"2023-10-15T01:24:47.654540Z","iopub.status.idle":"2023-10-15T01:24:47.680248Z","shell.execute_reply":"2023-10-15T01:24:47.679290Z","shell.execute_reply.started":"2023-10-15T01:24:47.655082Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>count</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>datasets/frames/seq_000001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>41</td>\n","      <td>datasets/frames/seq_000002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>41</td>\n","      <td>datasets/frames/seq_000003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>44</td>\n","      <td>datasets/frames/seq_000004.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>41</td>\n","      <td>datasets/frames/seq_000005.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  count                            path\n","0   1     35  datasets/frames/seq_000001.jpg\n","1   2     41  datasets/frames/seq_000002.jpg\n","2   3     41  datasets/frames/seq_000003.jpg\n","3   4     44  datasets/frames/seq_000004.jpg\n","4   5     41  datasets/frames/seq_000005.jpg"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def reconstruct_path(image_id):\n","    \"\"\"Превращает номерной ID изображения в относительный путь.\n","    \"\"\"\n","    image_id = str(image_id).rjust(6, '0')\n","    return f'datasets/frames/seq_{image_id}.jpg'\n","\n","\n","data['path'] = data['id'].apply(reconstruct_path)\n","data.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:47.683787Z","iopub.status.busy":"2023-10-15T01:24:47.683563Z","iopub.status.idle":"2023-10-15T01:24:47.695971Z","shell.execute_reply":"2023-10-15T01:24:47.695184Z","shell.execute_reply.started":"2023-10-15T01:24:47.683769Z"},"trusted":true},"outputs":[],"source":["def load_image(is_labelled, is_training=True):\n","    \"\"\"Загружает либо просто изображение, если ему не соответствует значение, либо изображение вместе со значением.\n","    \"\"\"\n","    def _get_image(path):\n","        \"\"\"Загружает изображение из файла и меняет его случайным образом.\n","        \"\"\"\n","        image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n","        image = tf.cast(image, dtype=tf.int32)\n","        image = tf.image.resize_with_pad(image, 299, 299)\n","        if is_training:\n","            image = tf.image.random_flip_left_right(image)\n","            image = tf.image.random_brightness(image, 0.1)\n","            image = tf.image.random_contrast(image, 0.1, 0.2)\n","            image = tf.image.random_saturation(image, 0.9, 1.1)\n","            image = tf.image.random_hue(image, 0.1)\n","        return tf.keras.applications.inception_resnet_v2.preprocess_input(image)\n","\n","    def _get_image_label(img, label):\n","        \"\"\"Загружает изображение вместе с соответствующим ему значением.\n","        \"\"\"\n","        return _get_image(img), label\n","\n","    return _get_image_label if is_labelled else _get_image\n","\n","\n","def prepare_dataset(dataset, is_training=True, is_labeled=True):\n","    \"\"\"Меняет датасет так, чтобы он содержал тензоры изображений и соответствующие им значения.\n","    \"\"\"\n","    image_read_fn = load_image(is_labeled, is_training)\n","    dataset = dataset.map(image_read_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    return dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","def create_model():\n","    \"\"\"Инициализирует модель, меняет её верхние слои, задаёт необходимые параметры.\n","    \"\"\"\n","    feature_model = tf.keras.applications.InceptionResNetV2(\n","        include_top=False, pooling='avg')\n","    feature_model.trainable = False\n","\n","    model = tf.keras.Sequential([\n","        tf.keras.Input((299, 299, 3)),\n","        feature_model,\n","        Dense(512, activation='selu'),\n","        Dense(1)\n","    ])\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n","                  loss=tf.keras.losses.MeanSquaredError(),\n","                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","    return model\n","\n","\n","def plot_history(hist):\n","    \"\"\"Создаёт график с оценкой обучения и ошибок.\n","    \"\"\"\n","    mae = hist.history['mean_absolute_error']\n","    val_mae = hist.history['val_mean_absolute_error']\n","    x_axis = range(1, len(mae) + 1)\n","    plt.plot(x_axis, mae, 'bo', label='Training')\n","    plt.plot(x_axis, val_mae, 'ro', label='Validation')\n","    plt.title('MAE')\n","    plt.legend()\n","    plt.xlabel('Epochs')\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:47.698474Z","iopub.status.busy":"2023-10-15T01:24:47.697733Z","iopub.status.idle":"2023-10-15T01:24:56.609496Z","shell.execute_reply":"2023-10-15T01:24:56.608611Z","shell.execute_reply.started":"2023-10-15T01:24:47.698398Z"},"trusted":true},"outputs":[],"source":["data_train = data.head(1700) #для обучения\n","data_valid = data.tail(300) #для проверки\n","\n","ds_train = tf.data.Dataset.from_tensor_slices((data_train['path'], data_train['count']))\n","ds_valid = tf.data.Dataset.from_tensor_slices((data_valid['path'], data_valid['count']))\n","\n","ds_train = prepare_dataset(ds_train)\n","ds_valid = prepare_dataset(ds_valid, is_training=False) #не для обучения, поэтому изображения изменяться не будут"]},{"cell_type":"markdown","metadata":{},"source":["# Часть 3: ResNet50"]},{"cell_type":"markdown","metadata":{},"source":["**Модель:** CNN (Свёрточная нейронная сеть) с 50 слоями, загружается из Keras. Включает в себя возможность изменить входной и выходные слои.\n","\n","#### Алгоритм\n","- Преобразовать изображения под формат входного слоя модели (сделаем формат изображений 224х224, минимальный для сетей ResNet).\n","- Загрузить модель, просмотреть её структуру и изменить верхние слои для нашей задачи.\n","- Обучить модель на данных датасета (при этом заморозив нижние слои) и определить, насколько хорошо она справляется с задачей распознавания человека в толпе."]},{"cell_type":"markdown","metadata":{},"source":["Загрузим модель и зададим ей необходимые параметры."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:56.611371Z","iopub.status.busy":"2023-10-15T01:24:56.610835Z","iopub.status.idle":"2023-10-15T01:24:59.279280Z","shell.execute_reply":"2023-10-15T01:24:59.278365Z","shell.execute_reply.started":"2023-10-15T01:24:56.611340Z"},"trusted":true},"outputs":[],"source":["resnet = resnet50.ResNet50(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(224, 224, 3),\n","    pooling='avg',\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:59.281144Z","iopub.status.busy":"2023-10-15T01:24:59.280645Z","iopub.status.idle":"2023-10-15T01:24:59.331797Z","shell.execute_reply":"2023-10-15T01:24:59.330958Z","shell.execute_reply.started":"2023-10-15T01:24:59.281112Z"},"trusted":true},"outputs":[],"source":["x = resnet.output\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(1, activation='linear')(x)\n","rn_model = tf.keras.Model(inputs=resnet.input, outputs=predictions)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:59.333882Z","iopub.status.busy":"2023-10-15T01:24:59.333240Z","iopub.status.idle":"2023-10-15T01:24:59.358797Z","shell.execute_reply":"2023-10-15T01:24:59.358054Z","shell.execute_reply.started":"2023-10-15T01:24:59.333839Z"},"trusted":true},"outputs":[],"source":["rn_model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n","    loss=\"mean_squared_error\",\n","    metrics=['mean_absolute_error', 'mean_squared_error',]\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:59.360534Z","iopub.status.busy":"2023-10-15T01:24:59.360007Z","iopub.status.idle":"2023-10-15T01:24:59.365483Z","shell.execute_reply":"2023-10-15T01:24:59.364746Z","shell.execute_reply.started":"2023-10-15T01:24:59.360505Z"},"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    validation_split=0.2,\n","    preprocessing_function=resnet50.preprocess_input,\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:24:59.369613Z","iopub.status.busy":"2023-10-15T01:24:59.369048Z","iopub.status.idle":"2023-10-15T01:25:05.188362Z","shell.execute_reply":"2023-10-15T01:25:05.187462Z","shell.execute_reply.started":"2023-10-15T01:24:59.369584Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1600 validated image filenames.\n","Found 400 validated image filenames.\n"]}],"source":["flow_params = dict(\n","    dataframe=data,\n","    x_col='path',\n","    y_col='count',\n","    weight_col=None,\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='raw',\n","    batch_size=4,\n","    shuffle=True,\n","    seed=0,\n",")\n","\n","train_generator = datagen.flow_from_dataframe(\n","    subset='training',\n","    **flow_params    \n",")\n","valid_generator = datagen.flow_from_dataframe(\n","    subset='validation',\n","    **flow_params\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:25:05.189819Z","iopub.status.busy":"2023-10-15T01:25:05.189488Z","iopub.status.idle":"2023-10-15T01:25:05.200155Z","shell.execute_reply":"2023-10-15T01:25:05.199108Z","shell.execute_reply.started":"2023-10-15T01:25:05.189794Z"},"trusted":true},"outputs":[],"source":["for layer in rn_model.layers[:-8]:\n","    layer.trainable = False\n","for layer in rn_model.layers[-8:]:\n","    layer.trainable = True"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:25:05.202106Z","iopub.status.busy":"2023-10-15T01:25:05.201452Z","iopub.status.idle":"2023-10-15T01:25:05.208948Z","shell.execute_reply":"2023-10-15T01:25:05.207936Z","shell.execute_reply.started":"2023-10-15T01:25:05.202074Z"},"trusted":true},"outputs":[],"source":["tf.debugging.set_log_device_placement(True)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-15T01:25:05.210561Z","iopub.status.busy":"2023-10-15T01:25:05.210176Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\MoreTech5\\cvv2.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MoreTech5/cvv2.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MoreTech5/cvv2.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m rn_model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_generator, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, ) \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MoreTech5/cvv2.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MoreTech5/cvv2.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rn_time \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(end \u001b[39m-\u001b[39m start, \u001b[39m2\u001b[39m)\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n","File \u001b[1;32md:\\MoreTech5\\MoreTech\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start = time.process_time()\n","history = rn_model.fit(train_generator, epochs=10, validation_data=valid_generator, verbose=2, ) \n","end = time.process_time()\n","rn_time = round(end - start, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mae_rn = history.history['mean_absolute_error'][49]\n","mse_rn = history.history['mean_squared_error'][49]\n","print(f'Validation MSE = {mse_rn}\\n'\n","      f'Validation MAE = {mae_rn}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rn_model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# rn_model.save('/kaggle/working/model_crowd_count.h5')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"}},"nbformat":4,"nbformat_minor":4}
